{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histopathologic Cancer Detection: Model Architecture\n",
    "\n",
    "In this notebook, we'll design, implement, and train models for the Histopathologic Cancer Detection task. We'll explore different architectures, preprocessing techniques, and training strategies to develop effective models for identifying metastatic cancer in histopathology images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading\n",
    "\n",
    "First, let's import the necessary libraries and load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "# TensorFlow and Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, GlobalAveragePooling2D, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50, EfficientNetB0, VGG16, MobileNetV2\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, confusion_matrix, classification_report\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Set plot style\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "# Check if GPU is available\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "print(\"TensorFlow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths to the dataset\n",
    "BASE_DIR = '../data'\n",
    "TRAIN_DIR = os.path.join(BASE_DIR, 'train')\n",
    "TEST_DIR = os.path.join(BASE_DIR, 'test')\n",
    "TRAIN_LABELS_PATH = os.path.join(BASE_DIR, 'train_labels.csv')\n",
    "\n",
    "# Load the training labels\n",
    "try:\n",
    "    train_labels = pd.read_csv(TRAIN_LABELS_PATH)\n",
    "    print(f\"Successfully loaded training labels with shape: {train_labels.shape}\")\n",
    "    print(\"\\nSample of training labels:\")\n",
    "    display(train_labels.head())\n",
    "    \n",
    "    # Check class distribution\n",
    "    class_distribution = train_labels['label'].value_counts().sort_index()\n",
    "    print(\"\\nClass distribution:\")\n",
    "    for label, count in class_distribution.items():\n",
    "        print(f\"Class {label} ({'Normal' if label == 0 else 'Metastatic Cancer'}): {count} ({count/len(train_labels)*100:.2f}%)\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading training labels: {e}\")\n",
    "    print(\"Please ensure the dataset is downloaded and the paths are correctly set.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing and Augmentation\n",
    "\n",
    "Before we design our models, let's establish our data preprocessing and augmentation pipeline. Proper preprocessing is crucial for achieving good performance in deep learning models, especially for medical imaging tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Image Loading and Normalization\n",
    "\n",
    "First, we need to load the images and normalize their pixel values. Normalization helps the model converge faster and achieve better performance by ensuring that all input features are on a similar scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_image(image_id, directory, target_size=(96, 96), normalize=True):\n",
    "    \"\"\"Load and preprocess an image from the specified directory\"\"\"\n",
    "    try:\n",
    "        img_path = os.path.join(directory, f\"{image_id}.tif\")\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "        \n",
    "        # Resize if needed\n",
    "        if img.shape[:2] != target_size:\n",
    "            img = cv2.resize(img, target_size)\n",
    "        \n",
    "        # Normalize pixel values to [0, 1]\n",
    "        if normalize:\n",
    "            img = img.astype(np.float32) / 255.0\n",
    "        \n",
    "        return img\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading image {image_id}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Train/Validation/Test Split\n",
    "\n",
    "We'll split our data into training, validation, and test sets. The training set is used to train the model, the validation set is used to tune hyperparameters and monitor performance during training, and the test set is used for final evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and validation sets\n",
    "train_df, val_df = train_test_split(\n",
    "    train_labels, \n",
    "    test_size=0.2,  # 20% for validation\n",
    "    random_state=42,\n",
    "    stratify=train_labels['label']  # Ensure class balance in both sets\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {len(train_df)}\")\n",
    "print(f\"Validation set size: {len(val_df)}\")\n",
    "\n",
    "# Check class distribution in the splits\n",
    "print(\"\\nClass distribution in training set:\")\n",
    "train_class_dist = train_df['label'].value_counts(normalize=True) * 100\n",
    "for label, percentage in train_class_dist.items():\n",
    "    print(f\"Class {label}: {percentage:.2f}%\")\n",
    "\n",
    "print(\"\\nClass distribution in validation set:\")\n",
    "val_class_dist = val_df['label'].value_counts(normalize=True) * 100\n",
    "for label, percentage in val_class_dist.items():\n",
    "    print(f\"Class {label}: {percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Data Augmentation\n",
    "\n",
    "Data augmentation is a technique to artificially expand the training dataset by creating modified versions of the existing images. This helps prevent overfitting and improves the model's ability to generalize to new data.\n",
    "\n",
    "For histopathology images, appropriate augmentation techniques include:\n",
    "\n",
    "1. **Rotation**: Cells and tissue structures can appear in any orientation\n",
    "2. **Flipping**: Horizontal and vertical flips don't change the medical interpretation\n",
    "3. **Slight zooming**: Simulates variations in magnification\n",
    "4. **Brightness/contrast adjustments**: Accounts for staining variations\n",
    "5. **Slight shifts**: Helps the model focus on the relevant features regardless of their exact position\n",
    "\n",
    "We'll use Keras' ImageDataGenerator to apply these augmentations during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data augmentation for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,  # Normalize pixel values\n",
    "    rotation_range=90,  # Random rotations up to 90 degrees\n",
    "    width_shift_range=0.1,  # Random horizontal shifts\n",
    "    height_shift_range=0.1,  # Random vertical shifts\n",
    "    shear_range=0.1,  # Shear transformations\n",
    "    zoom_range=0.1,  # Random zooming\n",
    "    horizontal_flip=True,  # Random horizontal flips\n",
    "    vertical_flip=True,  # Random vertical flips\n",
    "    fill_mode='nearest',  # Strategy for filling in newly created pixels\n",
    "    brightness_range=[0.9, 1.1]  # Random brightness adjustments\n",
    ")\n",
    "\n",
    "# For validation, we only need to normalize the pixel values\n",
    "val_datagen = ImageDataGenerator(\n",
    "    rescale=1./255\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Visualize Augmented Images\n",
    "\n",
    "Let's visualize some examples of augmented images to ensure our augmentation pipeline is working as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_augmentations(image_id, directory, datagen, num_augmentations=5):\n",
    "    \"\"\"Visualize augmentations applied to a single image\"\"\"\n",
    "    # Load the original image\n",
    "    img = load_and_preprocess_image(image_id, directory, normalize=False)\n",
    "    if img is None:\n",
    "        return\n",
    "    \n",
    "    # Reshape for the data generator (batch_size=1)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    \n",
    "    # Create an iterator for the augmented images\n",
    "    aug_iter = datagen.flow(img, batch_size=1)\n",
    "    \n",
    "    # Plot the original and augmented images\n",
    "    plt.figure(figsize=(15, 4))\n",
    "    \n",
    "    # Original image\n",
    "    plt.subplot(1, num_augmentations + 1, 1)\n",
    "    plt.imshow(img[0].astype(np.uint8))\n",
    "    plt.title('Original')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Augmented images\n",
    "    for i in range(num_augmentations):\n",
    "        aug_img = next(aug_iter)[0]\n",
    "        plt.subplot(1, num_augmentations + 1, i + 2)\n",
    "        plt.imshow((aug_img * 255).astype(np.uint8))\n",
    "        plt.title(f'Augmentation {i+1}')\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize augmentations for a normal tissue sample\n",
    "normal_sample = train_df[train_df['label'] == 0].sample(1)['id'].values[0]\n",
    "print(f\"Augmentations for Normal Tissue Sample (ID: {normal_sample})\")\n",
    "visualize_augmentations(normal_sample, TRAIN_DIR, train_datagen)\n",
    "\n",
    "# Visualize augmentations for a cancer tissue sample\n",
    "cancer_sample = train_df[train_df['label'] == 1].sample(1)['id'].values[0]\n",
    "print(f\"Augmentations for Cancer Tissue Sample (ID: {cancer_sample})\")\n",
    "visualize_augmentations(cancer_sample, TRAIN_DIR, train_datagen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Data Generators\n",
    "\n",
    "Now, let's create data generators for training and validation. These generators will load and preprocess images in batches, which is more memory-efficient than loading the entire dataset at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_generators(train_df, val_df, train_dir, batch_size=32):\n",
    "    \"\"\"Create data generators for training and validation\"\"\"\n",
    "    # Training generator with augmentation\n",
    "    train_generator = train_datagen.flow_from_dataframe(\n",
    "        dataframe=train_df,\n",
    "        directory=train_dir,\n",
    "        x_col='id',\n",
    "        y_col='label',\n",
    "        target_size=(96, 96),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary',\n",
    "        validate_filenames=False,  # Skip validation for speed\n",
    "        shuffle=True,\n",
    "        seed=42\n",
    "    )\n",
    "    \n",
    "    # Validation generator without augmentation\n",
    "    val_generator = val_datagen.flow_from_dataframe(\n",
    "        dataframe=val_df,\n",
    "        directory=train_dir,\n",
    "        x_col='id',\n",
    "        y_col='label',\n",
    "        target_size=(96, 96),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary',\n",
    "        validate_filenames=False,  # Skip validation for speed\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    return train_generator, val_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data generators\n",
    "batch_size = 32\n",
    "train_generator, val_generator = create_data_generators(train_df, val_df, TRAIN_DIR, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Architectures\n",
    "\n",
    "Now, let's design and implement different model architectures for the histopathologic cancer detection task. We'll explore three main approaches:\n",
    "\n",
    "1. Custom CNN from scratch\n",
    "2. Transfer learning with pre-trained models\n",
    "3. Vision transformers\n",
    "\n",
    "For each approach, we'll discuss its strengths, weaknesses, and suitability for histopathology image analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Custom CNN from Scratch\n",
    "\n",
    "Building a custom CNN from scratch gives us full control over the architecture and allows us to tailor it specifically to our task. This approach is useful when we have domain-specific knowledge about the problem or when pre-trained models might not be suitable.\n",
    "\n",
    "**Strengths:**\n",
    "- Full control over architecture design\n",
    "- Can be tailored specifically for histopathology images\n",
    "- Potentially smaller and faster than pre-trained models\n",
    "- Better interpretability due to simpler architecture\n",
    "\n",
    "**Weaknesses:**\n",
    "- Requires more data to train effectively\n",
    "- May not capture complex patterns as well as deeper pre-trained models\n",
    "- Requires more hyperparameter tuning\n",
    "- May take longer to converge\n",
    "\n",
    "**Why it might work for histopathology:**\n",
    "- Histopathology images have specific characteristics (cell structures, tissue patterns) that a custom CNN can be designed to detect\n",
    "- The task is relatively focused (binary classification of a specific type of cancer)\n",
    "- The image size is manageable (96x96 pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_custom_cnn(input_shape=(96, 96, 3)):\n",
    "    \"\"\"Create a custom CNN model for histopathology image classification\"\"\"\n",
    "    model = Sequential([\n",
    "        # First convolutional block\n",
    "        Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape),\n",
    "        Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.25),\n",
    "        \n",
    "        # Second convolutional block\n",
    "        Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.25),\n",
    "        \n",
    "        # Third convolutional block\n",
    "        Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.25),\n",
    "        \n",
    "        # Fourth convolutional block\n",
    "        Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "        Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.25),\n",
    "        \n",
    "        # Flatten and dense layers\n",
    "        Flatten(),\n",
    "        Dense(512, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation='sigmoid')  # Binary classification\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create and compile the custom CNN model\n",
    "custom_cnn = create_custom_cnn()\n",
    "custom_cnn.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]\n",
    ")\n",
    "\n",
    "# Display model summary\n",
    "custom_cnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Architecture Explanation:**\n",
    "\n",
    "Our custom CNN consists of four convolutional blocks, each followed by max pooling, batch normalization, and dropout:\n",
    "\n",
    "1. **Convolutional Blocks**: Each block contains two convolutional layers with increasing filter sizes (32 → 64 → 128 → 256). This allows the network to learn increasingly complex features.\n",
    "   \n",
    "2. **Max Pooling**: Reduces spatial dimensions, making the network more computationally efficient and helping it focus on the most important features.\n",
    "   \n",
    "3. **Batch Normalization**: Normalizes the activations of the previous layer, which helps with faster convergence and reduces the risk of overfitting.\n",
    "   \n",
    "4. **Dropout**: Randomly sets a fraction of input units to 0 during training, which helps prevent overfitting.\n",
    "   \n",
    "5. **Dense Layers**: After flattening, we have a dense layer with 512 units, followed by the output layer with a sigmoid activation function for binary classification.\n",
    "\n",
    "This architecture is designed to capture both low-level features (like edges and textures) and high-level features (like cell structures and tissue patterns) in histopathology images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Transfer Learning with Pre-trained Models\n",
    "\n",
    "Transfer learning involves using a pre-trained model (trained on a large dataset like ImageNet) as a starting point and fine-tuning it for our specific task. This approach leverages the knowledge learned from a large and diverse dataset, which can be beneficial even for specialized tasks like histopathology image analysis.\n",
    "\n",
    "**Strengths:**\n",
    "- Leverages knowledge from pre-training on large datasets\n",
    "- Requires less data to achieve good performance\n",
    "- Often converges faster during training\n",
    "- Can capture complex patterns and features\n",
    "\n",
    "**Weaknesses:**\n",
    "- Pre-trained models are typically trained on natural images, which differ from histopathology images\n",
    "- Larger models with more parameters, which can lead to overfitting\n",
    "- Higher computational requirements\n",
    "- Less interpretable due to complex architectures\n",
    "\n",
    "**Why it might work for histopathology:**\n",
    "- Despite differences between natural and histopathology images, low-level features (edges, textures) are still relevant\n",
    "- Pre-trained models have learned robust feature representations that can generalize to new domains\n",
    "- Fine-tuning allows the model to adapt to the specific characteristics of histopathology images\n",
    "\n",
    "We'll implement transfer learning with three popular architectures: ResNet50, EfficientNetB0, and MobileNetV2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_transfer_learning_model(base_model_name, input_shape=(96, 96, 3), trainable=False):\n",
    "    \"\"\"Create a transfer learning model using a pre-trained base model\"\"\"\n",
    "    # Select the base model\n",
    "    if base_model_name == 'resnet50':\n",
    "        base_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    elif base_model_name == 'efficientnet':\n",
    "        base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    elif base_model_name == 'mobilenet':\n",
    "        base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported base model: {base_model_name}\")\n",
    "    \n",
    "    # Freeze the base model if not trainable\n",
    "    base_model.trainable = trainable\n",
    "    \n",
    "    # Create the model\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    x = base_model(inputs, training=False)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    outputs = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = Model(inputs, outputs)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and compile the ResNet50 model\n",
    "resnet_model = create_transfer_learning_model('resnet50', trainable=False)\n",
    "resnet_model.compile(\n",
    "    optimizer=Adam(learning_rate=0.0001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]\n",
    ")\n",
    "\n",
    "# Display model summary\n",
    "print(\"ResNet50 Transfer Learning Model:\")\n",
    "resnet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and compile the EfficientNetB0 model\n",
    "efficientnet_model = create_transfer_learning_model('efficientnet', trainable=False)\n",
    "efficientnet_model.compile(\n",
    "    optimizer=Adam(learning_rate=0.0001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]\n",
    ")\n",
    "\n",
    "# Display model summary\n",
    "print(\"EfficientNetB0 Transfer Learning Model:\")\n",
    "efficientnet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and compile the MobileNetV2 model\n",
    "mobilenet_model = create_transfer_learning_model('mobilenet', trainable=False)\n",
    "mobilenet_model.compile(\n",
    "    optimizer=Adam(learning_rate=0.0001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]\n",
    ")\n",
    "\n",
    "# Display model summary\n",
    "print(\"MobileNetV2 Transfer Learning Model:\")\n",
    "mobilenet_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Architecture Explanation:**\n",
    "\n",
    "For our transfer learning models, we're using pre-trained networks (ResNet50, EfficientNetB0, and MobileNetV2) as feature extractors. Here's how our architecture works:\n",
    "\n",
    "1. **Pre-trained Base Model**: We use the convolutional layers of the pre-trained model (without the top classification layers) to extract features from our images. Initially, we freeze these layers to preserve the learned features.\n",
    "\n",
    "2. **Global Average Pooling**: This reduces the spatial dimensions of the feature maps, resulting in a fixed-size feature vector regardless of input size.\n",
    "\n",
    "3. **Custom Top Layers**: We add our own fully connected layers on top of the base model:\n",
    "   - A dropout layer to prevent overfitting\n",
    "   - A dense layer with ReLU activation to learn task-specific features\n",
    "   - Batch normalization to stabilize training\n",
    "   - Another dropout layer\n",
    "   - A final output layer with sigmoid activation for binary classification\n",
    "\n",
    "This approach allows us to leverage the powerful feature extraction capabilities of pre-trained models while adapting them to our specific task of histopathologic cancer detection."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
